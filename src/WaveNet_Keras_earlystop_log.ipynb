{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huixWaL42uZi"
   },
   "source": [
    "The validation scheme is based on [seq2seq-rnn-with-gru](https://www.kaggle.com/brandenkmurray/seq2seq-rnn-with-gru/output), and cleaned data is from [data-without-drift](https://www.kaggle.com/cdeotte/data-without-drift) and Kalman filter is from [https://www.kaggle.com/teejmahal20/single-model-lgbm-kalman-filter](single-model-lgbm-kalman-filter) and the added feature is from [wavenet-with-1-more-feature](wavenet-with-1-more-feature). I also used ragnar's data in this version [clean-kalman](https://www.kaggle.com/ragnar123/clean-kalman). The Wavenet is based on [https://github.com/philipperemy/keras-tcn](https://github.com/philipperemy/keras-tcn), [https://github.com/peustr/wavenet](https://github.com/peustr/wavenet) and [https://github.com/basveeling/wavenet](https://github.com/basveeling/wavenet) and also [https://www.kaggle.com/wimwim/wavenet-lstm](https://www.kaggle.com/wimwim/wavenet-lstm). If any refrence is not mentioned it was not intentional, please add them in comments.\n",
    "\n",
    "Previous versions were mainly based on [https://www.kaggle.com/wimwim/wavenet-lstm](https://www.kaggle.com/wimwim/wavenet-lstm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oTZ8BL4dHiC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.121605Z",
     "start_time": "2020-04-11T02:14:22.792317Z"
    },
    "_kg_hide-input": true,
    "colab": {},
    "colab_type": "code",
    "id": "LqmWjeYJ2uZn"
   },
   "outputs": [],
   "source": [
    "!pip install --no-warn-conflicts -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.152214Z",
     "start_time": "2020-04-11T02:14:24.125295Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "y1qOuodBfSxN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (TimeDistributed, Dropout, BatchNormalization, Flatten, Convolution1D, Activation, Input, Dense, LSTM, Lambda, Bidirectional,\n",
    "                                     Add, AveragePooling1D, Multiply, GRU, GRUCell, LSTMCell, SimpleRNNCell, SimpleRNN, TimeDistributed, RNN,\n",
    "                                     RepeatVector, Conv1D, MaxPooling1D, Concatenate, GlobalAveragePooling1D, UpSampling1D)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error\n",
    "# from tensorflow.keras.experimental import export_saved_model, load_from_saved_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\n",
    "from logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from contextlib import contextmanager\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "import tensorflow_addons as tfa\n",
    "import scipy.stats as stats\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "import time\n",
    "import pywt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "LC8XqE14cSRm",
    "outputId": "2ce313ab-88e5-4d72-d26f-70a22c47b22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Smart and Connected Everything_LTO2015_April 2 2014.pptx',\n",
       " '无标题绘图.gdraw',\n",
       " 'Smart and Connected Everything_LTO2015_April 2 2014.pptx.gslides',\n",
       " 'Class mytest.gdoc',\n",
       " '简历.gdoc',\n",
       " '2018.10.14.pdf',\n",
       " 'Learning notebook',\n",
       " 'Verification',\n",
       " 'da6ca21e-d8e3-4f08-816e-da2ac02f192f.pdf',\n",
       " 'Colab Notebooks',\n",
       " 'Course1FinalProject',\n",
       " 'CARLA',\n",
       " 'resulting_data.csv.gsheet',\n",
       " 'Patents.gdoc',\n",
       " 'Coursera_Self-Driving Cars_Toronto',\n",
       " 'Python programming',\n",
       " 'Tensorflow_CS20SI',\n",
       " 'Paper reading',\n",
       " '无标题文档 (2).gdoc',\n",
       " 'forms for H4.pdf',\n",
       " 'forms for H4.gdoc',\n",
       " '无标题文档 (1).gdoc',\n",
       " 'SVO.gdoc',\n",
       " '无标题文档.gdoc',\n",
       " 'YuanLin_CV_update2.pdf',\n",
       " 'YuanLin_CV.pdf',\n",
       " 'CV.gdoc',\n",
       " '博士论文_HC.doc',\n",
       " '博士论文_HC.pdf',\n",
       " 'models',\n",
       " 'CenterNetMask2-Aug-DrLr.ipynb',\n",
       " 'predictions-b4augmaskonelr40th-0.85.csv',\n",
       " 'setup.ipynb',\n",
       " 'CES2020 - VE Tech Forum.key',\n",
       " 'log-64-1e-3-aug.csv',\n",
       " 'log-1e-4-128-aug.csv',\n",
       " 'log.csv',\n",
       " 'tmp',\n",
       " 'ion_switch',\n",
       " 'predictions',\n",
       " 'CSDN',\n",
       " 'Untitled',\n",
       " 'wavenet_es_f0_checkpoint.h5',\n",
       " 'WaveNet.log',\n",
       " 'submission.csv',\n",
       " 'oof.npy',\n",
       " 'preds.npy',\n",
       " 'wavenet_es_f0_len1000_checkpoint.h5',\n",
       " 'wavenet_es_f0_len4000_gru_attention_checkpoint.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# path = \"/content/drive/My Drive\"\n",
    "\n",
    "# os.chdir(path)\n",
    "# os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.159766Z",
     "start_time": "2020-04-11T02:14:24.155918Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zdosugVWcOf0"
   },
   "outputs": [],
   "source": [
    "# PATH = '/kaggle/input/'\n",
    "# PATH = '/Users/helen/Desktop/Data/'\n",
    "PATH = 'ion_switch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.168634Z",
     "start_time": "2020-04-11T02:14:24.163612Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UafJMtyefSxU"
   },
   "outputs": [],
   "source": [
    "EPOCHS=120\n",
    "NNBATCHSIZE=20\n",
    "BATCHSIZE = 4000\n",
    "SEED = 321\n",
    "SELECT = True\n",
    "SPLITS = 5\n",
    "LR = 0.001\n",
    "fe_config = [\n",
    "    (True, BATCHSIZE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efFrvkxKx4Pu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iT_5jSWabrWx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90VRXbPAbctT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.177661Z",
     "start_time": "2020-04-11T02:14:24.171732Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EE4v8h1tfSxb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def init_logger():\n",
    "    handler = StreamHandler()\n",
    "    handler.setLevel(INFO)\n",
    "    handler.setFormatter(Formatter(LOGFORMAT))\n",
    "    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n",
    "    fh_handler.setFormatter(Formatter(LOGFORMAT))\n",
    "    logger.setLevel(INFO)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(fh_handler)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.184621Z",
     "start_time": "2020-04-11T02:14:24.180014Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7nxcdN_5fSxo"
   },
   "outputs": [],
   "source": [
    "\n",
    "@contextmanager\n",
    "def timer(name : Text):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "COMPETITION = 'ION-Switching'\n",
    "logger = getLogger(COMPETITION)\n",
    "LOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\n",
    "MODELNAME = 'WaveNet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.358957Z",
     "start_time": "2020-04-11T02:14:24.187096Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OC5DOcDifSxx"
   },
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed : int) -> NoReturn :\n",
    "    \n",
    "    rn.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    # os.environ['TF_CUDNN_DETERMINISTIC'] = str(seed) \n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIIuP3G5zeyM"
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNeG248jzBfL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjHllRRlh23Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkvHvTbfhZtw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sulbtdmIhoXQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.368249Z",
     "start_time": "2020-04-11T02:14:24.362616Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "adUHGQUTfSyA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_data(base : os.path.abspath) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    train = pd.read_csv(PATH+'clean-kalman/train_clean_kalman.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n",
    "    test  = pd.read_csv(PATH+'clean-kalman/test_clean_kalman.csv', dtype={'time': np.float32, 'signal': np.float32})\n",
    "    sub  = pd.read_csv(PATH+'liverpool-ion-switching/sample_submission.csv', dtype={'time': np.float32})\n",
    "    \n",
    "    return train, test, sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.376185Z",
     "start_time": "2020-04-11T02:14:24.371687Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HpDaJQ5yfSyI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def batching(df : pd.DataFrame,\n",
    "             batch_size : int) -> pd.DataFrame :\n",
    "    \n",
    "    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n",
    "    df['group'] = df['group'].astype(np.uint16)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.391087Z",
     "start_time": "2020-04-11T02:14:24.378989Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iQxOYF3tfSyj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def reduce_mem_usage(df: pd.DataFrame,\n",
    "                     verbose: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "\n",
    "                if (c_min > np.iinfo(np.int32).min\n",
    "                      and c_max < np.iinfo(np.int32).max):\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif (c_min > np.iinfo(np.int64).min\n",
    "                      and c_max < np.iinfo(np.int64).max):\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (c_min > np.finfo(np.float32).min\n",
    "                      and c_max < np.finfo(np.float32).max):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    reduction = (start_mem - end_mem) / start_mem\n",
    "\n",
    "    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bErHLyq0FTVf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4SHewOJFh_D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.402186Z",
     "start_time": "2020-04-11T02:14:24.393787Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dytmNmL_fSzj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def lag_with_pct_change(df : pd.DataFrame,\n",
    "                        shift_sizes : Optional[List]=[1, 2],\n",
    "                        add_pct_change : Optional[bool]=False,\n",
    "                        add_pct_change_lag : Optional[bool]=False) -> pd.DataFrame:\n",
    "    \n",
    "    for shift_size in shift_sizes:    \n",
    "        df['signal_shift_pos_'+str(shift_size)] = df.groupby('group')['signal'].shift(shift_size).fillna(0)\n",
    "        df['signal_shift_neg_'+str(shift_size)] = df.groupby('group')['signal'].shift(-1*shift_size).fillna(0)\n",
    "\n",
    "    if add_pct_change:\n",
    "        df['pct_change'] = df['signal'].pct_change()\n",
    "        if add_pct_change_lag:\n",
    "            for shift_size in shift_sizes:    \n",
    "                df['pct_change_shift_pos_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(shift_size).fillna(0)\n",
    "                df['pct_change_shift_neg_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(-1*shift_size).fillna(0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.409381Z",
     "start_time": "2020-04-11T02:14:24.404800Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m-ULWLF_fS0B"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_feat_enginnering(df : pd.DataFrame,\n",
    "                         create_all_data_feats : bool,\n",
    "                         batch_size : int) -> pd.DataFrame:\n",
    "    \n",
    "    df = batching(df, batch_size=batch_size)\n",
    "    if create_all_data_feats:\n",
    "        df = lag_with_pct_change(df, [1, 2, 3],  add_pct_change=False, add_pct_change_lag=False)\n",
    "    df['signal_2'] = df['signal'] ** 2\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.419991Z",
     "start_time": "2020-04-11T02:14:24.412368Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6E87jcu2fS0O"
   },
   "outputs": [],
   "source": [
    "def feature_selection(df : pd.DataFrame,\n",
    "                      df_test : pd.DataFrame) -> Tuple[pd.DataFrame , pd.DataFrame, List]:\n",
    "    use_cols = [col for col in df.columns if col not in ['index','group', 'open_channels', 'time']]\n",
    "    print(use_cols)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n",
    "    for col in use_cols:\n",
    "        col_mean = pd.concat([df[col], df_test[col]], axis=0).mean()\n",
    "        df[col] = df[col].fillna(col_mean)\n",
    "        df_test[col] = df_test[col].fillna(col_mean)\n",
    "   \n",
    "    gc.collect()\n",
    "    return df, df_test, use_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yyIkrTro-Xp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.427483Z",
     "start_time": "2020-04-11T02:14:24.422535Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ft7_2jVZcOgQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment(X: np.array, y:np.array) -> Tuple[np.array, np.array]:\n",
    "    \n",
    "    X = np.vstack((X, np.flip(X, axis=1)))\n",
    "    y = np.vstack((y, np.flip(y, axis=1)))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.432964Z",
     "start_time": "2020-04-11T02:14:24.430264Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Y-nODxu7cOgS"
   },
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "# saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.438940Z",
     "start_time": "2020-04-11T02:14:24.436211Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VRzoz-eacOgU"
   },
   "outputs": [],
   "source": [
    "# # %% [code] {\"ExecuteTime\":{\"end_time\":\"2020-04-03T23:24:41.652529Z\",\"start_time\":\"2020-04-03T23:24:41.645025Z\"}}\n",
    "# class EarlyStopping:\n",
    "#     def __init__(self, patience=5, delta=0, checkpoint_path='checkpoint.pt', is_maximize=True):\n",
    "#         self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "#         self.counter, self.best_score = 0, None\n",
    "#         self.is_maximize = is_maximize\n",
    "\n",
    "#     def load_best_weights(self, sess):\n",
    "#         saver.restore(sess, self.checkpoint_path)\n",
    "\n",
    "#     def __call__(self, score, sess):\n",
    "#         if self.best_score is None or \\\n",
    "#         (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "#             saver.save(sess, self.checkpoint_path)\n",
    "#             self.best_score, self.counter = score, 0\n",
    "#         else:\n",
    "#             self.counter += 1\n",
    "#             if self.counter >= self.patience:\n",
    "#                 return True\n",
    "#         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.477074Z",
     "start_time": "2020-04-11T02:14:24.441269Z"
    },
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "e4QulGxHfS0n"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_cv_model_by_batch(train : pd.DataFrame,\n",
    "                          test : pd.DataFrame,\n",
    "                          splits : int,\n",
    "                          batch_col : Text,\n",
    "                          feats : List,\n",
    "                          sample_submission: pd.DataFrame,\n",
    "                          nn_epochs : int,\n",
    "                          nn_batch_size : int) -> NoReturn:\n",
    "    seed_everything(SEED)\n",
    "    K.clear_session()\n",
    "    config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    oof_ = np.zeros((len(train), 11))\n",
    "    preds_ = np.zeros((len(test), 11))\n",
    "    target = ['open_channels']\n",
    "    group = train['group']\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    splits = [x for x in kf.split(train, train[target], group)]\n",
    "\n",
    "    new_splits = []\n",
    "    for sp in splits:\n",
    "        new_split = []\n",
    "        new_split.append(np.unique(group[sp[0]]))\n",
    "        new_split.append(np.unique(group[sp[1]]))\n",
    "        new_split.append(sp[1])    \n",
    "        new_splits.append(new_split)\n",
    "        \n",
    "    tr = pd.concat([pd.get_dummies(train.open_channels), train[['group']]], axis=1)\n",
    "\n",
    "    tr.columns = ['target_'+str(i) for i in range(11)] + ['group']\n",
    "    print(tr.head())\n",
    "    target_cols = ['target_'+str(i) for i in range(11)]\n",
    "    train_tr = np.array(list(tr.groupby('group').apply(lambda x: x[target_cols].values))).astype(np.float32)\n",
    "#     print(np.shape(train_tr))\n",
    "    train = np.array(list(train.groupby('group').apply(lambda x: x[feats].values)))\n",
    "#     print(np.shape(train))\n",
    "    test = np.array(list(test.groupby('group').apply(lambda x: x[feats].values)))\n",
    "#     print(np.shape(test))\n",
    "\n",
    "    for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(new_splits[0:], start=0):\n",
    "        \n",
    "        if n_fold > 0:\n",
    "            break\n",
    "        \n",
    "        train_x, train_y = train[tr_idx], train_tr[tr_idx]\n",
    "        valid_x, valid_y = train[val_idx], train_tr[val_idx]\n",
    "        \n",
    "        if n_fold < 2:\n",
    "            train_x, train_y = augment(train_x, train_y)\n",
    "\n",
    "        gc.collect()\n",
    "        shape_ = (None, train_x.shape[2])\n",
    "        model = Classifier(shape_)\n",
    "        print(\"model initilization done!\")\n",
    "        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "        cb_prg = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False,leave_overall_progress=False, \n",
    "                                               show_epoch_progress=False,show_overall_progress=True)\n",
    "        save_checkpoint_path = './wavenet_es_f{}_len4000_gru_attention_checkpoint.h5'.format(n_fold)\n",
    "        model.fit(train_x,train_y,\n",
    "                  epochs=nn_epochs,\n",
    "                  callbacks=[cb_prg, cb_lr_schedule, \n",
    "                             MacroF1ES(model, valid_x, valid_y, patience=20, delta=0, \n",
    "                                       checkpoint_path=save_checkpoint_path)],\n",
    "                  batch_size=nn_batch_size,verbose=0,\n",
    "                  validation_data=(valid_x,valid_y))\n",
    "        del model\n",
    "        model = tf.keras.models.load_model(save_checkpoint_path, custom_objects={'Activation': tf.keras.layers.Activation})\n",
    "        preds_f = model.predict(valid_x)\n",
    "        f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  \n",
    "                             np.argmax(preds_f, axis=2).reshape(-1), average = 'macro')\n",
    "        logger.info(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
    "        preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n",
    "        oof_[val_orig_idx,:] += preds_f\n",
    "        te_preds = model.predict(test)\n",
    "        te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n",
    "        preds_ += te_preds / SPLITS\n",
    "\n",
    "    f1_score_ =f1_score(np.argmax(train_tr, axis=2).reshape(-1),  np.argmax(oof_, axis=1), average = 'macro')\n",
    "    logger.info(f'Training completed. oof macro f1 score : {f1_score_:1.5f}')\n",
    "    sample_submission['open_channels'] = np.argmax(preds_, axis=1).astype(int)\n",
    "    sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\n",
    "    display(sample_submission.head())\n",
    "    np.save('oof.npy', oof_)\n",
    "    np.save('preds.npy', preds_)\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laBDOG5mBo9p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_xP2z13BaUh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3R-iTvAzQIu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.485692Z",
     "start_time": "2020-04-11T02:14:24.479620Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dqt0VJAS2ucB"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    if epoch < 40:\n",
    "        lr = LR\n",
    "    elif epoch < 50:\n",
    "        lr = LR / 3\n",
    "    elif epoch < 60:\n",
    "        lr = LR / 6\n",
    "    elif epoch < 75:\n",
    "        lr = LR / 9\n",
    "    elif epoch < 85:\n",
    "        lr = LR / 12\n",
    "    elif epoch < 100:\n",
    "        lr = LR / 15\n",
    "    else:\n",
    "        lr = LR / 50\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5b1Dn35b6J9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.499088Z",
     "start_time": "2020-04-11T02:14:24.488223Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SjbrEQSa2ucN"
   },
   "outputs": [],
   "source": [
    "class Mish(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Mish, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "def mish(x):\n",
    "\treturn tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n",
    " \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "# from tensorflow.keras.layers import Activation\n",
    "get_custom_objects().update({'mish': Activation(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74K9iBMJcIzh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.521416Z",
     "start_time": "2020-04-11T02:14:24.502541Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dM8RiNfL2ucY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import constraints\n",
    "\n",
    "class Attention(Layer):\n",
    "    \"\"\"Multi-headed attention layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, \n",
    "                 num_heads = 8, \n",
    "                 attention_dropout=.1,\n",
    "                 trainable=True,\n",
    "                 name='Attention'):\n",
    "        \n",
    "        if hidden_size % num_heads != 0:\n",
    "            raise ValueError(\"Hidden size must be evenly divisible by the number of heads.\")\n",
    "            \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.trainable = trainable\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.dense = tf.keras.layers.Dense(self.hidden_size, use_bias=False)\n",
    "        super(Attention, self).__init__(name=name)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"Split x into different heads, and transpose the resulting value.\n",
    "        The tensor is transposed to insure the inner dimensions hold the correct\n",
    "        values during the matrix multiplication.\n",
    "        Args:\n",
    "          x: A tensor with shape [batch_size, length, hidden_size]\n",
    "        Returns:\n",
    "          A tensor with shape [batch_size, num_heads, length, hidden_size/num_heads]\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"split_heads\"):\n",
    "            batch_size = tf.shape(x)[0]\n",
    "            length = tf.shape(x)[1]\n",
    "\n",
    "            # Calculate depth of last dimension after it has been split.\n",
    "            depth = (self.hidden_size // self.num_heads)\n",
    "\n",
    "            # Split the last dimension\n",
    "            x = tf.reshape(x, [batch_size, length, self.num_heads, depth])\n",
    "\n",
    "            # Transpose the result\n",
    "            return tf.transpose(x, [0, 2, 1, 3])\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"Combine tensor that has been split.\n",
    "        Args:\n",
    "          x: A tensor [batch_size, num_heads, length, hidden_size/num_heads]\n",
    "        Returns:\n",
    "          A tensor with shape [batch_size, length, hidden_size]\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"combine_heads\"):\n",
    "            batch_size = tf.shape(x)[0]\n",
    "            length = tf.shape(x)[2]\n",
    "            x = tf.transpose(x, [0, 2, 1, 3])  # --> [batch, length, num_heads, depth]\n",
    "            return tf.reshape(x, [batch_size, length, self.hidden_size])        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Apply attention mechanism to inputs.\n",
    "        Args:\n",
    "          inputs: a tensor with shape [batch_size, length_x, hidden_size]\n",
    "        Returns:\n",
    "          Attention layer output with shape [batch_size, length_x, hidden_size]\n",
    "        \"\"\"\n",
    "        # Google developper use tf.layer.Dense to linearly project the queries, keys, and values.\n",
    "        q = self.dense(inputs)\n",
    "        k = self.dense(inputs)\n",
    "        v = self.dense(inputs)\n",
    "\n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "        \n",
    "        # Scale q to prevent the dot product between q and k from growing too large.\n",
    "        depth = (self.hidden_size // self.num_heads)\n",
    "        q *= depth ** -0.5\n",
    "        \n",
    "        logits = tf.matmul(q, k, transpose_b=True)\n",
    "        # logits += self.bias\n",
    "        weights = tf.nn.softmax(logits, name=\"attention_weights\")\n",
    "        \n",
    "        if self.trainable:\n",
    "            weights = tf.nn.dropout(weights, 1.0 - self.attention_dropout)\n",
    "        \n",
    "        attention_output = tf.matmul(weights, v)\n",
    "        attention_output = self.combine_heads(attention_output)\n",
    "        attention_output = self.dense(attention_output)\n",
    "        return attention_output\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.531056Z",
     "start_time": "2020-04-11T02:14:24.524047Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bG4cGcYYNVYw"
   },
   "outputs": [],
   "source": [
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss from the paper in multiclass classification\n",
    "    Formula:\n",
    "        loss = -alpha*((1-p)^gamma)*log(p)\n",
    "    Parameters:\n",
    "        alpha -- the same as wighting factor in balanced cross entropy\n",
    "        gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "        gamma -- 2.0 as mentioned in the paper\n",
    "        alpha -- 0.25 as mentioned in the paper\n",
    "    \"\"\"\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        # Clip the prediction value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true*K.log(y_pred)\n",
    "        # Calculate weight that consists of  modulating factor and weighting factor\n",
    "        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.549703Z",
     "start_time": "2020-04-11T02:14:24.533479Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YSESlpaNwkkx"
   },
   "outputs": [],
   "source": [
    "def WaveNetResidualConv1D(num_filters, kernel_size, stacked_layer):\n",
    "\n",
    "    def build_residual_block(l_input):\n",
    "        resid_input = l_input\n",
    "        for dilation_rate in [2**i for i in range(stacked_layer)]:\n",
    "            l_sigmoid_conv1d = Conv1D(\n",
    "              num_filters, kernel_size, dilation_rate=dilation_rate,\n",
    "              padding='same', activation='sigmoid')(l_input)\n",
    "            l_tanh_conv1d = Conv1D(\n",
    "             num_filters, kernel_size, dilation_rate=dilation_rate,\n",
    "             padding='same', activation='mish')(l_input)\n",
    "            l_input = Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n",
    "            l_input = Conv1D(num_filters, 1, padding='same')(l_input)\n",
    "            resid_input = Add()([resid_input ,l_input])\n",
    "        return resid_input\n",
    "    return build_residual_block\n",
    "\n",
    "def Classifier(shape_):\n",
    "    num_filters_ = 16\n",
    "    kernel_size_ = 3\n",
    "    stacked_layers_ = [12, 8, 4, 1]\n",
    "    l_input = Input(shape=(shape_))\n",
    "    x = Conv1D(num_filters_, 1, padding='same')(l_input)\n",
    "    x = WaveNetResidualConv1D(num_filters_, kernel_size_, stacked_layers_[0])(x)\n",
    "    x = Conv1D(num_filters_*2, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*2, kernel_size_, stacked_layers_[1])(x)\n",
    "    x = Conv1D(num_filters_*4, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*4, kernel_size_, stacked_layers_[2])(x)\n",
    "    x = Conv1D(num_filters_*8, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*8, kernel_size_, stacked_layers_[3])(x)\n",
    "    l_output = Dense(11, activation='softmax')(x)\n",
    "    model = models.Model(inputs=[l_input], outputs=[l_output])\n",
    "    opt = Adam(lr=LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "#      MacroF1(model, valid_x,valid_y)\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(), optimizer=opt, \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnR2IhRSj8Gc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.563702Z",
     "start_time": "2020-04-11T02:14:24.556844Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9Cckpy4I2uco"
   },
   "outputs": [],
   "source": [
    "def Classifierx(shape_):        \n",
    "    #dsize = [256, 512, 256, 128, 11]\n",
    "    dsize = [64, 128, 64, 32, 11]  \n",
    "    inp = Input(shape=(shape_))\n",
    "    x = Bidirectional(GRU(dsize[0], return_sequences=True))(inp)\n",
    "    x = Attention(dsize[1])(x)\n",
    "    x = TimeDistributed(Dense(dsize[2], activation='mish'))(x)\n",
    "    x = TimeDistributed(Dense(dsize[3], activation='mish'))(x)\n",
    "    out = TimeDistributed(Dense(dsize[4], activation='softmax', name='out'))(x)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=out) \n",
    "    \n",
    "    opt = Adam(lr=LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(), optimizer=opt, \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19HDmUd3EKGX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEa1XkhnD7ch"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1J-enJgDszG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aw_HBSPfebIy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.579491Z",
     "start_time": "2020-04-11T02:14:24.567764Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "L4cQ0L8ucOgn"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MacroF1ES(Callback):\n",
    "    def __init__(self, model, inputs, targets, \n",
    "                 patience=5, delta=0, checkpoint_path='checkpoint.h5', is_maximize=True):\n",
    "        \n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "        self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "        self.counter, self.best_score = 0, None\n",
    "        self.is_maximize = is_maximize\n",
    "        self.stopped_epoch = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "        score = f1_score(self.targets, pred, average=\"macro\")\n",
    "        print(f' F1Macro: {score:.5f}')   \n",
    "        \n",
    "        if self.best_score is None or \\\n",
    "        (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "            self.model.save(self.checkpoint_path)\n",
    "#             torch.save(model.state_dict(), self.checkpoint_path)\n",
    "            self.best_score, self.counter = score, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience: ##stop training\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "              print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.589759Z",
     "start_time": "2020-04-11T02:14:24.582640Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1yfpldH_2ucw"
   },
   "outputs": [],
   "source": [
    "class MacroF1(Callback):\n",
    "    def __init__(self, model, inputs, targets):\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "        score = f1_score(self.targets, pred, average=\"macro\")\n",
    "        print(f' F1Macro: {score:.5f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.596693Z",
     "start_time": "2020-04-11T02:14:24.591931Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "skru4lPt2uc6"
   },
   "outputs": [],
   "source": [
    "def normalize(train, test):\n",
    "    \n",
    "    train_input_mean = train.signal.mean()\n",
    "    train_input_sigma = train.signal.std()\n",
    "    train['signal'] = (train.signal-train_input_mean)/train_input_sigma\n",
    "    test['signal'] = (test.signal-train_input_mean)/train_input_sigma\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:14:24.609602Z",
     "start_time": "2020-04-11T02:14:24.600166Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "02TDJtejfS0_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_everything(fe_config : List) -> NoReturn:\n",
    "    not_feats_cols = ['time']\n",
    "    target_col = ['open_channels']\n",
    "    init_logger()\n",
    "    with timer(f'Reading Data'):\n",
    "        logger.info('Reading Data Started ...')\n",
    "        base = os.path.abspath(PATH+'liverpool-ion-switching/')\n",
    "        train, test, sample_submission = read_data(base)\n",
    "        train, test = normalize(train, test)    \n",
    "        logger.info('Reading and Normalizing Data Completed ...')\n",
    "    with timer(f'Creating Features'):\n",
    "        logger.info('Feature Enginnering Started ...')\n",
    "        for config in fe_config:\n",
    "            train = run_feat_enginnering(train, create_all_data_feats=config[0], batch_size=config[1])\n",
    "            test  = run_feat_enginnering(test,  create_all_data_feats=config[0], batch_size=config[1])\n",
    "        train, test, feats = feature_selection(train, test)\n",
    "        logger.info('Feature Enginnering Completed ...')\n",
    "\n",
    "    with timer(f'Running Wavenet model'):\n",
    "        logger.info(f'Training Wavenet model with {SPLITS} folds of GroupKFold Started ...')\n",
    "        run_cv_model_by_batch(train, test, splits=SPLITS, batch_col='group', feats=feats, \n",
    "                              sample_submission=sample_submission, nn_epochs=EPOCHS, nn_batch_size=NNBATCHSIZE)\n",
    "        logger.info(f'Training completed ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T02:15:53.901793Z",
     "start_time": "2020-04-11T02:14:24.612467Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545,
     "referenced_widgets": [
      "4ae37b2325364bfa9d61b560646806e7",
      "c1295e4de4aa4155b796c79c8fb28ef2",
      "5defed4e266c4b2eae667f19ce0369fc",
      "70544bf266ff491d9c90445d5791512d",
      "f73547b0deaa4a0e917a00253f9192f4",
      "ab28e8d6f15f4b09a02be5d0c4e06535",
      "601d35f3432e4bf685d9af7b10a781fb",
      "2f481699a95743db9971088e60a488ee"
     ]
    },
    "colab_type": "code",
    "id": "_w4_OJJtfS1K",
    "outputId": "2932d13d-4b46-442f-e5ef-6a6b0d84a053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:20:21,003 INFO Reading Data Started ...\n",
      "2020-04-11 21:20:23,680 INFO Reading and Normalizing Data Completed ...\n",
      "2020-04-11 21:20:23,685 INFO [Reading Data] done in 3 s\n",
      "2020-04-11 21:20:23,687 INFO Feature Enginnering Started ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signal', 'signal_shift_pos_1', 'signal_shift_neg_1', 'signal_shift_pos_2', 'signal_shift_neg_2', 'signal_shift_pos_3', 'signal_shift_neg_3', 'signal_2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:20:28,134 INFO Feature Enginnering Completed ...\n",
      "2020-04-11 21:20:28,139 INFO [Creating Features] done in 4 s\n",
      "2020-04-11 21:20:28,141 INFO Training Wavenet model with 5 folds of GroupKFold Started ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_0  target_1  target_2  target_3  target_4  target_5  target_6  \\\n",
      "0         1         0         0         0         0         0         0   \n",
      "1         1         0         0         0         0         0         0   \n",
      "2         1         0         0         0         0         0         0   \n",
      "3         1         0         0         0         0         0         0   \n",
      "4         1         0         0         0         0         0         0   \n",
      "\n",
      "   target_7  target_8  target_9  target_10  group  \n",
      "0         0         0         0          0      0  \n",
      "1         0         0         0          0      0  \n",
      "2         0         0         0          0      0  \n",
      "3         0         0         0          0      0  \n",
      "4         0         0         0          0      0  \n",
      "model initilization done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae37b2325364bfa9d61b560646806e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', layout=Layout(flex='2'), max=120, style=ProgressSt…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      " F1Macro: 0.90203\n",
      " F1Macro: 0.92839\n",
      " F1Macro: 0.92289\n"
     ]
    }
   ],
   "source": [
    "run_everything(fe_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6l-HSmYUHXK8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGEAzuNYHl0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cz8TkawgH0d7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZJrwUQfIDHa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ft4dtQE3IRw6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7KoItjuHIhh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sG-iypxpG54B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAMFhQeOGrOd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsQDkxfhGN7f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6pyNALRGck-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmE3KDrkFwoe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_paO96MF_R-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q579wepNEYvi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTcgPhGgEnlW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AodXpJDvd91u"
   },
   "outputs": [],
   "source": [
    "print(\"go go go\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WaveNet-Keras-earlystop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2f481699a95743db9971088e60a488ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ae37b2325364bfa9d61b560646806e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5defed4e266c4b2eae667f19ce0369fc",
       "IPY_MODEL_70544bf266ff491d9c90445d5791512d"
      ],
      "layout": "IPY_MODEL_c1295e4de4aa4155b796c79c8fb28ef2"
     }
    },
    "5defed4e266c4b2eae667f19ce0369fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Training:   2%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab28e8d6f15f4b09a02be5d0c4e06535",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f73547b0deaa4a0e917a00253f9192f4",
      "value": 3
     }
    },
    "601d35f3432e4bf685d9af7b10a781fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70544bf266ff491d9c90445d5791512d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f481699a95743db9971088e60a488ee",
      "placeholder": "​",
      "style": "IPY_MODEL_601d35f3432e4bf685d9af7b10a781fb",
      "value": " 3/120 ETA: 2:17:05s,  70.30s/epochs"
     }
    },
    "ab28e8d6f15f4b09a02be5d0c4e06535": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1295e4de4aa4155b796c79c8fb28ef2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f73547b0deaa4a0e917a00253f9192f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
