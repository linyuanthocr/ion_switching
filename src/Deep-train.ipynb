{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.765818Z",
     "start_time": "2020-04-05T21:47:26.744653Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "This version of TensorFlow Addons requires TensorFlow version >= 2.1.0; Detected an installation of version 2.0.0. Please upgrade TensorFlow to proceed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6512fb40e804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF1Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tf_install\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ensure_tf_install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0m_ensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py\u001b[0m in \u001b[0;36m_ensure_tf_install\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;34m\"version >= {required}; Detected an installation of version \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \"{present}. Please upgrade TensorFlow to proceed.\".format(\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mrequired\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequired_tensorflow_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             )\n\u001b[1;32m     43\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: This version of TensorFlow Addons requires TensorFlow version >= 2.1.0; Detected an installation of version 2.0.0. Please upgrade TensorFlow to proceed."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr  3 14:10:07 2019\n",
    "\n",
    "@author: ncelik34\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Importing the libraries\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Activation, LSTM, BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.768243Z",
     "start_time": "2020-04-05T21:47:26.744Z"
    }
   },
   "outputs": [],
   "source": [
    "def mcor(y_true, y_pred):\n",
    "    # Matthews correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.769434Z",
     "start_time": "2020-04-05T21:47:26.746Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_roc(true, predicted):\n",
    "\n",
    "    # roc curve plotting for multiple\n",
    "\n",
    "    n_classesi = predicted.shape[1]\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "\n",
    "    for i in range(n_classesi):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true[:, i], predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    colors = ['aqua', 'darkorange', 'cornflowerblue',\n",
    "                    'red', 'black', 'yellow']\n",
    "    for i in range(n_classesi):\n",
    "        plt.plot(fpr[i], tpr[i], color=color[i], lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('Zooom in View: Some extension of ROC to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.770624Z",
     "start_time": "2020-04-05T21:47:26.747Z"
    }
   },
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    # Learning rate scheduler object\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.001\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "'''\n",
    "############# SET UP RUN HERE ####################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.771603Z",
     "start_time": "2020-04-05T21:47:26.748Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# PATH = '/kaggle/input/'\n",
    "PATH = '/Users/helen/Desktop/Data/'\n",
    "\n",
    "df = pd.read_csv(PATH+'data-without-drift/train_clean.csv', header=None)\n",
    "dataset = df.values.astype('float64')\n",
    "timep = dataset[:, 0]\n",
    "maxer = np.amax(dataset[:, 2])\n",
    "maxeri = maxer.astype('int')\n",
    "maxchannels = maxeri\n",
    "idataset = dataset[:, 2].astype(int)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# train and test set split and reshape:\n",
    "train_size = int(len(dataset) * 0.80)\n",
    "modder = math.floor(train_size/batch_size)\n",
    "train_size = int(modder*batch_size)\n",
    "test_size = int(len(dataset) - train_size)\n",
    "modder = math.floor(test_size/batch_size)\n",
    "test_size = int(modder*batch_size)\n",
    "\n",
    "print(f'training set = {train_size}')\n",
    "print(f'test set = {test_size}')\n",
    "print(f'total length = {test_size + train_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.772596Z",
     "start_time": "2020-04-05T21:47:26.749Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = dataset[:, 1]\n",
    "y_train = idataset[:]\n",
    "x_train = x_train.reshape((len(x_train), 1))\n",
    "y_train = y_train.reshape((len(y_train), 1))\n",
    "\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_res, Y_res = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "yy_res = Y_res.reshape((len(Y_res), 1))\n",
    "yy_res = to_categorical(yy_res, num_classes=maxchannels+1)\n",
    "xx_res, yy_res = shuffle(X_res, yy_res)\n",
    "\n",
    "\n",
    "trainy_size = int(len(xx_res) * 0.80)\n",
    "modder = math.floor(trainy_size/batch_size)\n",
    "trainy_size = int(modder*batch_size)\n",
    "testy_size = int(len(xx_res) - trainy_size)\n",
    "modder = math.floor(testy_size/batch_size)\n",
    "testy_size = int(modder*batch_size)\n",
    "\n",
    "print('training set= ', trainy_size)\n",
    "print('test set =', testy_size)\n",
    "print('total length', testy_size+trainy_size)\n",
    "\n",
    "\n",
    "in_train, in_test = xx_res[0:trainy_size,\n",
    "                           0], xx_res[trainy_size:trainy_size+testy_size, 0]\n",
    "target_train, target_test = yy_res[0:trainy_size,\n",
    "                                   :], yy_res[trainy_size:trainy_size+testy_size, :]\n",
    "in_train = in_train.reshape(len(in_train), 1, 1, 1)\n",
    "in_test = in_test.reshape(len(in_test), 1, 1, 1)\n",
    "\n",
    "\n",
    "# validation set!!\n",
    "df_val = pd.read_csv(PATH+'data-without-drift/test_clean.csv', header=None)\n",
    "data_val = df_val.values.astype('float64')\n",
    "\n",
    "idataset2 = data_val[:, 2].astype(int)\n",
    "\n",
    "val_set = data_val[:, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "val_set = scaler.fit_transform(val_set.reshape(-1,1))\n",
    "val_set = val_set.reshape(len(val_set), 1, 1, 1)\n",
    "val_target = data_val[:, 2]\n",
    "val_target = to_categorical(val_target, num_classes=maxchannels+1)\n",
    "\n",
    "\n",
    "# model starts.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.773544Z",
     "start_time": "2020-04-05T21:47:26.751Z"
    }
   },
   "outputs": [],
   "source": [
    "newmodel = Sequential()\n",
    "timestep = 1\n",
    "input_dim = 1\n",
    "newmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=1,\n",
    "                                    activation='relu'), input_shape=(None, timestep, input_dim)))\n",
    "newmodel.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
    "newmodel.add(TimeDistributed(Flatten()))\n",
    "\n",
    "newmodel.add(LSTM(256, activation='relu', return_sequences=True))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.2))\n",
    "\n",
    "newmodel.add(LSTM(256, activation='relu', return_sequences=True))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.2))\n",
    "\n",
    "newmodel.add(LSTM(256, activation='relu'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.2))\n",
    "\n",
    "newmodel.add(Dense(maxchannels+1))\n",
    "newmodel.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "newmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False), metrics=[\n",
    "                 'accuracy', Precision(), Recall(), F1Score(num_classes=maxchannels+1, average='micro')])\n",
    "\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "\n",
    "epochers = 10\n",
    "history = newmodel.fit(x=in_train, y=target_train, initial_epoch=0, epochs=epochers, batch_size=batch_size, callbacks=[\n",
    "                       lrate], verbose=1, shuffle=False, validation_data=(in_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.774587Z",
     "start_time": "2020-04-05T21:47:26.753Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction for test set\n",
    "predict = newmodel.predict(in_test, batch_size=batch_size)\n",
    "\n",
    "# prediction for val set\n",
    "predict_val = newmodel.predict(val_set, batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_predict = np.argmax(predict, axis=-1)\n",
    "class_predict_val = np.argmax(predict_val, axis=-1)\n",
    "class_target = np.argmax(target_test, axis=-1)\n",
    "class_target_val = np.argmax(val_target, axis=-1)\n",
    "\n",
    "\n",
    "cm_test = confusion_matrix(class_target, class_predict)\n",
    "cm_val = confusion_matrix(idataset2, class_predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T21:47:26.775694Z",
     "start_time": "2020-04-05T21:47:26.754Z"
    }
   },
   "outputs": [],
   "source": [
    "rnd = 1\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig(str(rnd)+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig(str(rnd)+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plotlen = test_size\n",
    "lenny = 2000\n",
    "\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "# temp=scaler.inverse_transform(dataset)\n",
    "plt.plot(xx_res[trainy_size:trainy_size+lenny, 0],\n",
    "         color='blue', label=\"some raw data\")\n",
    "plt.title(\"The raw test\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(class_target[:lenny], color='black', label=\"the actual idealisation\", drawstyle='steps-mid')\n",
    "\n",
    "line, = plt.plot(class_predict[:lenny], color='red',\n",
    "                 label=\"predicted idealisation\", drawstyle='steps-mid')\n",
    "plt.setp(line, linestyle='--')\n",
    "plt.xlabel('timepoint')\n",
    "plt.ylabel('current')\n",
    "# plt.savefig(str(rnd)+'data.png')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# newmodel.save('nmn_oversampled_deepchanel6_5.h5')\n",
    "\n",
    "make_roc(val_target, predicted_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
